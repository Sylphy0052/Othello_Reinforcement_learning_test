# オセロAI開発（AlphaZero方式） 要件定義書

## 1. プロジェクト概要

### 1.1 目的

自己対戦のみを通じて学習する「AlphaZeroアプローチ」を採用し、人間の専門知識に依存しない強力なオセロAIを構築する。最終的には、一般ユーザーが手軽にAIと対戦できるGUIアプリケーションとして提供する。

### 1.2 開発フェーズ

* **フェーズ1（コア開発）:** 高速なオセロ環境と学習パイプラインの実装。
* **フェーズ2（学習・評価）:** GPUを用いた学習サイクルと、Edax（既存最強AI）とのベンチマーク。
* **フェーズ3（アプリ化）:** 学習済みモデルの軽量化とGUIの実装。

---

## 2. システム構成・技術スタック

| レイヤー | 技術選定 | 備考 |
| :--- | :--- | :--- |
| **言語** | Python 3.10+, **Cython** | 高速化が必要な環境部にCythonを採用 |
| **学習FW** | PyTorch | GPU活用、動的グラフ構築のため |
| **推論エンジン** | **ONNX Runtime** | GUIアプリ動作時の軽量化・高速化 |
| **GUI FW** | Tkinter または PySide6 | Python標準または高機能なQtラッパー |
| **ハードウェア** | NVIDIA GeForce RTX 4050 Laptop | 学習用。VRAM制約への対策が必要 |

---

## 3. 機能要件

### 3.1 オセロ環境（Game Environment）

Pythonのオーバーヘッドを排除するため、コアロジックをCythonで実装する。

* **ビットボード実装:** 盤面を `uint64` 2つ（自軍・敵軍）で表現し、ビット演算（シフト、AND、XOR）により合法手生成と石反転を行う。
* **高速API:** `get_legal_moves`, `make_move`, `is_terminal` 等の関数をCython（.pyx）で定義し、Pythonから直接インポート可能にする。

### 3.2 AIモデル（Neural Network）

AlphaZero方式のデュアルヘッドResNetを採用する。

* **入力:** $3 \times 8 \times 8$ テンソル（自軍石、敵軍石、合法手マスク）。
* **バックボーン:** ResNet（残差ブロック）。
  * **規模調整:** RTX 4050での学習効率を考慮し、まずは **10ブロック・128フィルタ** 程度から開始する（VRAM使用量監視により調整）。
* **出力:**
  * **Policy Head:** 65次元（各マスの着手確率 + パス）。
  * **Value Head:** スカラー（-1〜1 の勝率予測）。

### 3.3 探索・学習アルゴリズム

* **MCTS (モンテカルロ木探索):** ロールアウトを行わず、NNの価値出力を用いて探索を行う。
  * **Action Masking:** 合法手以外の確率を $-\infty$ マスク処理で無効化する。
* **学習ループ:**
    1. **Self-Play:** MCTSを用いて自己対戦データを生成。
    2. **Train:** バッファからサンプリングしてNNを更新。
    3. **Evaluate:** 新旧モデルを対戦させ、勝率55%超で更新。

### 3.4 GUIアプリケーション（対戦クライアント）

人間がAIと快適に対戦できるインターフェースを提供する。

* **対戦モード:** 人間 vs AI（先手・後手選択可）。
* **盤面表示:** 8x8のグリッド、石の配置、合法手のハイライト表示。
* **思考表示:** AIが検討中の手や評価値（形勢判断）を可視化する機能（オプション）。
* **モデル読込:** ONNX形式の学習済みモデルを読み込んで動作すること。

---

## 4. 非機能要件・制約事項

### 4.1 ハードウェア制約への対策（RTX 4050 Laptop）

Laptop GPU（想定VRAM 6GB）での学習を安定させるため、以下の対策を実装する。

* **混合精度学習 (Automatic Mixed Precision):** `torch.cuda.amp` を使用し、メモリ使用量を半減させつつ計算速度を向上させる。
* **バッチサイズの調整:** VRAM枯渇（OOM）を防ぐため、バッチサイズを動的に調整可能な設計とする（推奨初期値: 256〜512）。

### 4.2 パフォーマンス

* **自己対戦速度:** Cython実装により、1ワーカーあたり数百局面/秒以上の生成速度を目指す。
* **GUI応答性:** 人間の手番では遅延なく反応し、AI思考中もUIがフリーズしないよう、推論処理は別スレッドで実行する。

---

## 5. 開発ロードマップ

### Phase 1: 環境構築とCython実装（1〜2週間）

* プロジェクト構成の作成。
* Cythonによるビットボードクラスの実装。
* ランダムプレイヤーによる動作テストと速度ベンチマーク。

### Phase 2: 学習サイクルの構築（2〜3週間）

* PyTorchによるResNetモデルの実装。
* MCTSの実装とAction Maskingの適用。
* 自己対戦・学習・評価のループスクリプト作成。
* **マイルストーン:** 6x6盤面（または小規模ネットワーク）での学習成功を確認。

### Phase 3: 本格学習とチューニング（継続）

* 8x8盤面での長時間学習（RTX 4050稼働）。
* Edaxとの対戦による強さ測定。

### Phase 4: アプリケーション開発（1〜2週間）

* 学習済みモデルのONNXエクスポート。
* GUIの実装と統合。
